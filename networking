targetport: the port the container is listening on

port number : port number exposed internally inside a cluster

A Service enables network access to a set of Pods in Kubernetes.


kubectl create  deploy web  --image=nginx --dry-run=client -o yaml > web.yaml

kubectl expose deploy/web --type=ClusterIP --port=80 --dry-run=client -o yaml > clusterip.yaml

kubectl expose deployment/web  --type=LoadBalancer --port=80 --dry-run=client -o yaml > loadbalancer.yaml

kubectl expose deployment/web  --type=NodePort --port=80 --dry-run=client -o yaml > nodeport.yaml

. ClusterIP is the default and most common service type.
 Kubernetes will assign a cluster-internal IP address to ClusterIP service.
  This  makes the  service only reachable within the cluster.
 You cannot make requests to service (pods) from outside the cluster. 
 Inter service communication within the cluster


This service visible outside the Kubernetes cluster by the node’s IP address and the port number declared . 
The service also has  to be of type NodePort (if this field isn’t specified, Kubernetes will allocate a node port automatically). 
Node port must be in the range of 30000–32767. Manually allocating a port to the service is optional



 Every time you want to expose a service to the outside world, you have  to create a new        LoadBalancer  and get an IP address.
 It exposes the service externally using a cloud providers load Balancer
 Each cloud provider (AWS, Azure, GCP,) has its own native load balancer implementation. The cloud provider will create a load balancer, which then automatically routes requests to your Kubernetes Service.


Refer doc of nodeport - type search  services in kubernetes doc and we can refer for Nodeport and loadbalancer yamls and clusterip is default and can be generated
by below command

kubectl run nginx --image=nginx  --port=80 --expose --dry-run=client -o yaml


kubectl create  deploy web  --image=nginx --dry-run=client -o yaml > web.yaml

kubectl expose deploy/web --type=ClusterIP --port=80 --dry-run=client -o yaml > clusterip.yaml

kubectl expose deployment/web  --type=LoadBalancer --port=80 --dry-run=client -o yaml > loadbalancer.yaml

kubectl expose deployment/web  --type=NodePort --port=80 --dry-run=client -o yaml > nodeport.yaml


serives
======

.  A Service enables network access to a set of Pods in Kubernetes.
.  Kubernetes gives Pods their own IP addresses   and can load-balance across them


. ClusterIP is the default and most common service type.
 Kubernetes will assign a cluster-internal IP address to ClusterIP service.
  This  makes the  service only reachable within the cluster.
 You cannot make requests to service (pods) from outside the cluster. 
 Inter service communication within the cluster


=========================

NodePort:

. This service visible outside the Kubernetes cluster by the node’s IP address and the port number declared . 
  The service also has  to be of type NodePort (if this field isn’t specified, Kubernetes will allocate a node port automatically). 
. Node port must be in the range of 30000–32767. Manually allocating a port to the service is optional

Let’s take a closer look at the Service. If you look at it, there are 3 ports involved. The
port on the POD were the actual web server is running is port 80. And it is referred to
as the targetPort , because that is were the service forwards the requests to. The
second port is the port on the service itself. It is simply referred to as the port.
Remember, these terms are from the viewpoint of the service. The service is in fact
like a virtual server inside the node. Inside the cluster it has its own IP address. And
that IP address is called the Cluster IP of the service. And finally we have the port on
the Node itself which we use to access the web server externally. And that is known
as the NodePort . As you can see it is 30008. That is because NodePorts can only be in
a valid range which is from 30000 to 32767.

========================================

LoadBalancer:

 Every time you want to expose a service to the outside world, you have  to create a new        LoadBalancer  and get an IP address.
 It exposes the service externally using a cloud providers load Balancer
 Each cloud provider (AWS, Azure, GCP,) has its own native load balancer implementation. The cloud provider will create a load balancer, which then automatically routes requests to your Kubernetes Service.

================

https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/docs/02-Core-Concepts/19-Services.md
LoadBalacer
#https://github.com/dennyzhang/cheatsheet-kubernetes-A4

kubectl expose deployment/my-demo-website --type=LoadBalancer --dry-run=client -o yaml > svc.yaml
kubectl expose deployment/mydemo --type=LoadBalancer --dry-run=client -o yaml > svc.yaml

NodePort:
========
 kubectl expose deployment/mydemo --type=NodePort --dry-run=client -o yaml  >

ClusterIP:
========

https://matthewpalmer.net/kubernetes-app-developer/articles/service-kubernetes-example-tutorial.html

Cluster IP is a virtual IP that is allocated by the K8s to a service. It is K8s internal IP.

A Cluster IP makes it accessible from any of the Kubernetes cluster’s nodes. The use of virtual IP addresses for this purpose makes it possible to have several pods expose the same port on the same node – All of these pods will be accessible via a unique IP address.

This IP is stable and never changes in the service lifecycle(unless deleted explicitly).

2 different pods can communicate using this IP, though I recommend using cluster DNS service

kubectl expose deployment/mydemo --dry-run=client -o yaml

=========

