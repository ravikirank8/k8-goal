selector:
    app: myapp
 
labels:
   app: myapp

both  labels should be match for service for selector and label in pod/repicalset

289 page in ckd doc ingress


targetport: the port the container is listening on

port number : port number exposed internally inside a cluster

A Service enables network access to a set of Pods in Kubernetes.


kubectl create  deploy web  --image=nginx --dry-run=client -o yaml > web.yaml

kubectl expose deploy/web --type=ClusterIP --port=80 --dry-run=client -o yaml > clusterip.yaml

kubectl expose deployment/web  --type=LoadBalancer --port=80 --dry-run=client -o yaml > loadbalancer.yaml

kubectl expose deployment/web  --type=NodePort --port=80 --dry-run=client -o yaml > nodeport.yaml

. ClusterIP is the default and most common service type.
 Kubernetes will assign a cluster-internal IP address to ClusterIP service.
  This  makes the  service only reachable within the cluster.
 You cannot make requests to service (pods) from outside the cluster. 
 Inter service communication within the cluster


This service visible outside the Kubernetes cluster by the node’s IP address and the port number declared . 
The service also has  to be of type NodePort (if this field isn’t specified, Kubernetes will allocate a node port automatically). 
Node port must be in the range of 30000–32767. Manually allocating a port to the service is optional



 Every time you want to expose a service to the outside world, you have  to create a new        LoadBalancer  and get an IP address.
 It exposes the service externally using a cloud providers load Balancer
 Each cloud provider (AWS, Azure, GCP,) has its own native load balancer implementation. The cloud provider will create a load balancer, which then automatically routes requests to your Kubernetes Service.


Refer doc of nodeport - type search  services in kubernetes doc and we can refer for Nodeport and loadbalancer yamls and clusterip is default and can be generated
by below command

kubectl run nginx --image=nginx  --port=80 --expose --dry-run=client -o yaml


kubectl create  deploy web  --image=nginx --dry-run=client -o yaml > web.yaml

kubectl expose deploy/web --type=ClusterIP --port=80 --dry-run=client -o yaml > clusterip.yaml

kubectl expose deployment/web  --type=LoadBalancer --port=80 --dry-run=client -o yaml > loadbalancer.yaml

kubectl expose deployment/web  --type=NodePort --port=80 --dry-run=client -o yaml > nodeport.yaml


serives
======

.  A Service enables network access to a set of Pods in Kubernetes.
.  Kubernetes gives Pods their own IP addresses   and can load-balance across them


. ClusterIP is the default and most common service type.
 Kubernetes will assign a cluster-internal IP address to ClusterIP service.
  This  makes the  service only reachable within the cluster.
 You cannot make requests to service (pods) from outside the cluster. 
 Inter service communication within the cluster


=========================

NodePort:

. This service visible outside the Kubernetes cluster by the node’s IP address and the port number declared . 
  The service also has  to be of type NodePort (if this field isn’t specified, Kubernetes will allocate a node port automatically). 
. Node port must be in the range of 30000–32767. Manually allocating a port to the service is optional

Let’s take a closer look at the Service. If you look at it, there are 3 ports involved. The
port on the POD were the actual web server is running is port 80. And it is referred to
as the targetPort , because that is were the service forwards the requests to. The
second port is the port on the service itself. It is simply referred to as the port.
Remember, these terms are from the viewpoint of the service. The service is in fact
like a virtual server inside the node. Inside the cluster it has its own IP address. And
that IP address is called the Cluster IP of the service. And finally we have the port on
the Node itself which we use to access the web server externally. And that is known
as the NodePort . As you can see it is 30008. That is because NodePorts can only be in
a valid range which is from 30000 to 32767.

========================================

LoadBalancer:

 Every time you want to expose a service to the outside world, you have  to create a new        LoadBalancer  and get an IP address.
 It exposes the service externally using a cloud providers load Balancer
 Each cloud provider (AWS, Azure, GCP,) has its own native load balancer implementation. The cloud provider will create a load balancer, which then automatically routes requests to your Kubernetes Service.

================

https://github.com/kodekloudhub/certified-kubernetes-administrator-course/blob/master/docs/02-Core-Concepts/19-Services.md
LoadBalacer
#https://github.com/dennyzhang/cheatsheet-kubernetes-A4

kubectl expose deployment/my-demo-website --type=LoadBalancer --dry-run=client -o yaml > svc.yaml
kubectl expose deployment/mydemo --type=LoadBalancer --dry-run=client -o yaml > svc.yaml

NodePort:
========
 kubectl expose deployment/mydemo --type=NodePort --dry-run=client -o yaml  >

ClusterIP:
========

https://matthewpalmer.net/kubernetes-app-developer/articles/service-kubernetes-example-tutorial.html

Cluster IP is a virtual IP that is allocated by the K8s to a service. It is K8s internal IP.

A Cluster IP makes it accessible from any of the Kubernetes cluster’s nodes. The use of virtual IP addresses for this purpose makes it possible to have several pods expose the same port on the same node – All of these pods will be accessible via a unique IP address.

This IP is stable and never changes in the service lifecycle(unless deleted explicitly).

2 different pods can communicate using this IP, though I recommend using cluster DNS service

kubectl expose deployment/mydemo --dry-run=client -o yaml

=========
Ingress

To configure Ingress. The solution you deploy is called as an Ingress Controller. And
the set of rules you configure is called as Ingress Resources. Ingress resources are
created using definition files like the ones we used to create PODs, Deployments and
services earlier in this course.



In Kubernetes, an ingress is a set of rules that allow inbound connections to reach services running in a cluster

Think of it as a traffic controller that sits between the outside world and your cluster. 
When a user or an external system sends a request to access a specific service, the ingress will route the traffic to the appropriate service based on the 
defined rules. 

Ingress rules specify the host name, path, and backend service for each incoming request.
For example, an ingress rule could say that any request coming to "example.com/api" should be routed to the "api-service" running in the cluster. 

In addition to routing traffic, ingress also provides features such as SSL termination, load balancing, and name-based virtual hosting. 

Overall, ingress is a powerful tool that enables you to expose your Kubernetes services to the internet and manage incoming traffic efficiently.

Now remember a kubernetes cluster does NOT come with an Ingress Controller by
default. If you setup a cluster following the demos in this course, you won’t have an
Now

Article: Ingress
As we already discussed Ingress in our previous lecture. Here is an update.

In this article, we will see what changes have been made in previous and current versions in Ingress.

Like in apiVersion, serviceName and servicePort etc.


Now, in k8s version 1.20+ we can create an Ingress resource from the imperative way like this:-

Format - kubectl create ingress <ingress-name> --rule="host/path=service:port"

Example - kubectl create ingress ingress-test --rule="wear.my-online-store.com/wear*=wear-service:80"

Find more information and examples in the below reference link:-

https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#-em-ingress-em-

References:-

https://kubernetes.io/docs/concepts/services-networking/ingress

https://kubernetes.io/docs/concepts/services-networking/ingress/#path-types

=====================================================

You are requested to change the URLs at which the applications are made available.

Make the video application available at /stream

Run the command: kubectl edit ingress --namespace app-space and change the path to the video streaming application to /stream

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
  name: ingress-wear-watch
  namespace: app-space
spec:
  rules:
  - http:
      paths:
      - backend:
          service:
            name: wear-service
            port: 
              number: 8080
        path: /wear
        pathType: Prefix
      - backend:
          service:
            name: video-service
            port: 
              number: 8080
        path: /stream
        pathType: Prefix
        
        
        ===========
        
        You are requested to add a new path to your ingress to make the food delivery application available to your customers.

Make the new application available at /eat


Ingress: ingress-wear-watch
Path: /eat
Backend Service: food-service
Backend Service Port: 8080

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
  name: ingress-wear-watch
  namespace: app-space
spec:
  rules:
  - http:
      paths:
      - backend:
          service:
            name: wear-service
            port: 
              number: 8080
        path: /wear
        pathType: Prefix
      - backend:
          service:
            name: video-service
            port: 
              number: 8080
        path: /stream
        pathType: Prefix
      - backend:
          service:
            name: food-service
            port: 
              number: 8080
        path: /eat
        pathType: Prefix
        
        
        
        
        
        
        ===================================================
        
        
        You are requested to make the new application available at /pay.

Identify and implement the best approach to making this application available on the ingress controller
and test to make sure its working. Look into annotations: rewrite-target as well.

Ingress Created
Path: /pay
Configure correct backend service
Configure correct backend port

Create a new Ingress for the new pay application in the critical-space namespace.
Use the command kubectl get svc -n critical-space to know the service and port details.

Name:              pay-service
Namespace:         critical-space
Labels:            <none>
Annotations:       <none>
Selector:          app=webapp-pay
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.105.246.224
IPs:               10.105.246.224
Port:              <unset>  8282/TCP
TargetPort:        8080/TCP
Endpoints:         10.244.0.11:8080
Session Affinity:  None
Events:            <none>

you need take port in svc and put in the backend port number / serviceName in ing should equal to svc name(k get svc)

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: test-ingress
  namespace: critical-space
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  rules:
  - http:
      paths:
      - path: /pay
        pathType: Prefix
        backend:
          service:
           name: pay-service
           port:
            number: 8282
            
            =====================================
            
 Network policies
 
 We will start with a simple example of a traffic through a
web, app and database server. So you have a web server serving front-end to users,
an app server serving backend API’s and a database server. The user sends in a
request to the web server at port 80. The web server then sends a request to the API
server at port 5000 in the backend. The API server then fetches data from the
database server at port 3306. And then sends the data back to the user. A very
simple setup.
      
The NGINX Ingress Controller requires a ConfigMap object. Create a ConfigMap object in the ingress-space
kubectl create configmap nginx-configuration --namespace ingress-space

The NGINX Ingress Controller requires a ServiceAccount. Create a ServiceAccount in the ingress-space namespace
kubectl create serviceaccount ingress-serviceaccount --namespace ingress-space


========================================

Let us now create a service to make Ingress available to external users.
Create a service following the given specs.

Name: ingress
Type: NodePort
Port: 80
TargetPort: 80
NodePort: 30080
Namespace: ingress-space
Use the right selector

Use the command kubectl expose -n ingress-space deployment ingress-controller --type=NodePort --port=80 --name=ingress --dry-run=client -o yaml > ingress.yaml and manually add the given node port and namespace.

